{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Topic Labelling\n",
    "In this notebook we will be infering a label for each one of the topics obtained in the Topic Modelling notebook. The main process will be divided as follows:\n",
    "* We will begin by linking to [Wikidata](https://www.wikidata.org/wiki/Wikidata:Main_Page) each one of the terms that belong to each topic. (_Entity linking_)\n",
    "* After the entity linking step, we will generate a Graph with the neighbour nodes of each starting term by traversing their Wikidata information based on a set of properties to expand.\n",
    "* Once a graph is built for each topic, we will remove isolated subgraphs from them to obtain the main connected subgraph of each one.\n",
    "* We will apply a set of centrality algorithms to obtain the entity from Wikidata which best represents the topic subgraph. This node will be used as a label for the topic.\n",
    "* Finally, the topic labels will be added to the final model, which will be serialized for further use in the following notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "As always, we will begin by loading a set of constants and initializing the logging system. Since we will be using Bokeh in this notebook, we will configure it to output the results in the Jupyter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run __init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandro/.envs/edma/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.io import output_notebook\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity linking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the entity linking class\n",
    "An entity linking class has been defined in the _entity_linking.py_ module of the _src_ directory. This class will link the given words to their Wikidata entity by using the [wbsearchentities](https://www.wikidata.org/w/api.php?action=help&modules=wbsearchentities)Â modules from the MediaWiki API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('agroforestry', 'http://www.wikidata.org/entity/Q397350')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.entity_linking import WikidataEntityLinker\n",
    "\n",
    "entity_linker = WikidataEntityLinker()\n",
    "res = entity_linker.link_entity('agroforestry')\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linking each topic's term to Wikidata\n",
    "In the following cells we are going to load the lda model trained on the Agriculture dataset, obtain the term distribution of each topic, and link each term to Wikidata. We will start by loading both the LDA pipeline and the document term matrix with the term frequency: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import load_object\n",
    "\n",
    "lda_agriculture_pipe_filename = \"agriculture_lda_model.pkl\"\n",
    "dtm_tf_filename = \"agriculture_dtm_tf.pkl\"\n",
    "\n",
    "lda_pipe = load_object(os.path.join(NOTEBOOK_3_RESULTS_DIR, lda_agriculture_pipe_filename))\n",
    "dtm_tf = load_object(os.path.join(NOTEBOOK_3_RESULTS_DIR, dtm_tf_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain the list of terms for each topic, we are going to make use of the _get\\_topic\\_terms\\_by\\_relevance_ function to obtain a list of more relevant terms for each topic (see [Sievert & Shirley](https://nlp.stanford.edu/events/illvi2014/papers/sievert-illvi2014.pdf) for more information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import get_topic_terms_by_relevance\n",
    "\n",
    "def link_topic_terms(entity_linker, model, vectorizer,\n",
    "                     dtm_tf, n_top_words, lambda_=0.6):\n",
    "    res = []\n",
    "    topic_terms = get_topic_terms_by_relevance(model, vectorizer, dtm_tf,\n",
    "                                               n_top_words, lambda_)\n",
    "    return [[entity_linker.link_entity(entity) for entity in topic]\n",
    "            for topic in topic_terms]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can make used of the function defined above to link each term to Wikidata. The output of the following cell will be a 2D array, with the first dimension corresponding to each topic, and the second one consisting on tuples containing the pair ('term', 'wikidata_uri') for every term of the topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('food', 'http://www.wikidata.org/entity/Q2095'),\n",
       "  ('system', 'http://www.wikidata.org/entity/Q58778'),\n",
       "  ('habitat', 'http://www.wikidata.org/entity/Q52105'),\n",
       "  ('grassland', 'http://www.wikidata.org/entity/Q1006733'),\n",
       "  ('production', 'http://www.wikidata.org/entity/Q739302'),\n",
       "  ('agricultural', 'http://www.wikidata.org/entity/Q5356428'),\n",
       "  ('land', 'http://www.wikidata.org/entity/Q11081619'),\n",
       "  ('bird', 'http://www.wikidata.org/entity/Q5113'),\n",
       "  ('change', 'http://www.wikidata.org/entity/Q1150070'),\n",
       "  ('security', 'http://www.wikidata.org/entity/Q2526135')],\n",
       " [('plant', 'http://www.wikidata.org/entity/Q756'),\n",
       "  ('expression', 'http://www.wikidata.org/entity/Q11024'),\n",
       "  ('gene', 'http://www.wikidata.org/entity/Q7187'),\n",
       "  ('adaptation', 'http://www.wikidata.org/entity/Q3331189'),\n",
       "  ('root', 'http://www.wikidata.org/entity/Q111029'),\n",
       "  ('shoot', 'http://www.wikidata.org/entity/Q220869'),\n",
       "  ('site', 'http://www.wikidata.org/entity/Q35127'),\n",
       "  ('diversification', 'http://www.wikidata.org/entity/Q731453'),\n",
       "  ('Arabidopsis', 'http://www.wikidata.org/entity/Q157892'),\n",
       "  ('heat', 'http://www.wikidata.org/entity/Q44432')],\n",
       " [('base', 'http://www.wikidata.org/entity/Q191360'),\n",
       "  ('system', 'http://www.wikidata.org/entity/Q58778'),\n",
       "  ('sensor', 'http://www.wikidata.org/entity/Q167676'),\n",
       "  ('agricultural', 'http://www.wikidata.org/entity/Q5356428'),\n",
       "  ('node', 'http://www.wikidata.org/entity/Q756100'),\n",
       "  ('breeding', 'http://www.wikidata.org/entity/Q227675'),\n",
       "  ('farming', 'http://www.wikidata.org/entity/Q11451'),\n",
       "  ('technology', 'http://www.wikidata.org/entity/Q11016'),\n",
       "  ('crop', 'http://www.wikidata.org/entity/Q235352'),\n",
       "  ('agriculture', 'http://www.wikidata.org/entity/Q11451')],\n",
       " [('soil', 'http://www.wikidata.org/entity/Q36133'),\n",
       "  ('rice', 'http://www.wikidata.org/entity/Q5090'),\n",
       "  ('crop', 'http://www.wikidata.org/entity/Q235352'),\n",
       "  ('yield', 'http://www.wikidata.org/entity/Q889514'),\n",
       "  ('high', 'http://www.wikidata.org/entity/Q1617718'),\n",
       "  ('practice', 'http://www.wikidata.org/entity/Q30028999'),\n",
       "  ('residue', 'http://www.wikidata.org/entity/Q753375'),\n",
       "  ('increase', 'http://www.wikidata.org/entity/Q17281278'),\n",
       "  ('study', 'http://www.wikidata.org/entity/Q1298668'),\n",
       "  ('fertilizer', 'http://www.wikidata.org/entity/Q83323')],\n",
       " [('plant', 'http://www.wikidata.org/entity/Q756'),\n",
       "  ('stress', 'http://www.wikidata.org/entity/Q123414'),\n",
       "  ('gene', 'http://www.wikidata.org/entity/Q7187'),\n",
       "  ('increase', 'http://www.wikidata.org/entity/Q17281278'),\n",
       "  ('level', 'http://www.wikidata.org/entity/Q1046315'),\n",
       "  ('root', 'http://www.wikidata.org/entity/Q111029'),\n",
       "  ('treatment', 'http://www.wikidata.org/entity/Q179661'),\n",
       "  ('protein', 'http://www.wikidata.org/entity/Q8054'),\n",
       "  ('expression', 'http://www.wikidata.org/entity/Q11024'),\n",
       "  ('acid', 'http://www.wikidata.org/entity/Q11158')],\n",
       " [('rodent', 'http://www.wikidata.org/entity/Q10850'),\n",
       "  ('grain', 'http://www.wikidata.org/entity/Q2995529'),\n",
       "  ('crop', 'http://www.wikidata.org/entity/Q235352'),\n",
       "  ('genotype', 'http://www.wikidata.org/entity/Q106016'),\n",
       "  ('line', 'http://www.wikidata.org/entity/Q166154'),\n",
       "  ('study', 'http://www.wikidata.org/entity/Q1298668'),\n",
       "  ('repellent', 'http://www.wikidata.org/entity/Q1340459'),\n",
       "  ('livestock', 'http://www.wikidata.org/entity/Q103459'),\n",
       "  ('LMW', 'http://www.wikidata.org/entity/Q3820396'),\n",
       "  ('gliadin', 'http://www.wikidata.org/entity/Q279074')],\n",
       " [('plant', 'http://www.wikidata.org/entity/Q756'),\n",
       "  ('transgenic', 'http://www.wikidata.org/entity/Q7834239'),\n",
       "  ('light', 'http://www.wikidata.org/entity/Q9128'),\n",
       "  ('growth', 'http://www.wikidata.org/entity/Q1342838'),\n",
       "  ('line', 'http://www.wikidata.org/entity/Q166154'),\n",
       "  ('Arabidopsis', 'http://www.wikidata.org/entity/Q157892'),\n",
       "  ('PSII', 'http://www.wikidata.org/entity/Q49920346'),\n",
       "  ('protein', 'http://www.wikidata.org/entity/Q8054'),\n",
       "  ('level', 'http://www.wikidata.org/entity/Q1046315'),\n",
       "  ('transcript', 'http://www.wikidata.org/entity/Q2448947')],\n",
       " [('plant', 'http://www.wikidata.org/entity/Q756'),\n",
       "  ('medicinal', 'http://www.wikidata.org/entity/Q188840'),\n",
       "  ('decoction', 'http://www.wikidata.org/entity/Q1136912'),\n",
       "  ('Herb', 'http://www.wikidata.org/entity/Q207123'),\n",
       "  ('informant', 'http://www.wikidata.org/entity/Q1364673'),\n",
       "  ('take', 'http://www.wikidata.org/entity/Q1124733'),\n",
       "  ('orally', 'http://www.wikidata.org/entity/Q40832683'),\n",
       "  ('Wild', 'http://www.wikidata.org/entity/Q206357'),\n",
       "  ('use', 'http://www.wikidata.org/entity/Q1724915'),\n",
       "  ('area', 'http://www.wikidata.org/entity/Q11500')],\n",
       " [('plant', 'http://www.wikidata.org/entity/Q756'),\n",
       "  ('root', 'http://www.wikidata.org/entity/Q111029'),\n",
       "  ('infect', 'http://www.wikidata.org/entity/Q808'),\n",
       "  ('virus', 'http://www.wikidata.org/entity/Q808'),\n",
       "  ('non', 'http://www.wikidata.org/entity/Q848640'),\n",
       "  ('gene', 'http://www.wikidata.org/entity/Q7187'),\n",
       "  ('endophyte', 'http://www.wikidata.org/entity/Q260335'),\n",
       "  ('tomato', 'http://www.wikidata.org/entity/Q23501'),\n",
       "  ('inoculate', 'http://www.wikidata.org/entity/Q44575524'),\n",
       "  ('control', 'http://www.wikidata.org/entity/Q11175')]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linked_terms = link_topic_terms(entity_linker, lda_pipe.named_steps['model'],\n",
    "                                lda_pipe.named_steps['vectorizer'], dtm_tf, \n",
    "                                n_top_words=10, lambda_=0.8)\n",
    "linked_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining each topic's graphs\n",
    "In this phase we are going to explore the neighbourhood of each term linked before, to obtain a graph with their related terms from Wikidata. Each set of terms obtained before will be the seed concepts used to obtain the final graph, and a set of properties from Wikidata will be explored recursively to expand the final graph. \n",
    "\n",
    "For more information about the implementation of the graph building process, the class used can be accessed at the _graph.py_ module in the source directory.\n",
    "\n",
    "In the following cell we will be configuring the graph builder to build a graph with a maxium depth of two from every seed node. Higher depth values might cause the resulting topic labels to be very general, while with a smaller value we have the risk of not obtaining a connection between the seed nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.graph import WikidataGraphBuilder\n",
    "\n",
    "graph_builder = WikidataGraphBuilder(max_hops=2)\n",
    "topic_graphs = [graph_builder.build_graph(topic) for topic in linked_terms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have obtained the neighbourhood graph of each topic, we are going to plot the results using bokeh. Each node will have a different color depending on their depth with respect to the seed nodes, which will be painted in blue. This will allow us to perform an initial exploration of these graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bokeh.io import show\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "from src.graph import build_graph_plot\n",
    "\n",
    "\n",
    "plots = [build_graph_plot(g, f\"Topic {idx}\") \n",
    "         for idx, g in enumerate(topic_graphs)]\n",
    "grid = gridplot(plots, ncols=2)\n",
    "show(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An optimum result would be to have every seed term connected in the final graph. However, theere will be some subgraphs which are isolated from the main ones. In the following section we will be solving this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the main connected subgraph\n",
    "As we have described before, some of the topic graphs that we have obtained are not fully connected. Small subgraphs which are isolated from the main subgraph will be considered as noise, and removed before the following computations.\n",
    "\n",
    "In the following cells, we are going to retrieve the largest connected subgraph from each topic's graph, and plot the results to anaylise them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.graph import get_largest_connected_subgraph\n",
    "\n",
    "connected_topic_subgraphs = [get_largest_connected_subgraph(g) \n",
    "                             for g in topic_graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plots = [build_graph_plot(g, f\"Largest Connected subgraph for topic {idx}\") \n",
    "         for idx, g in enumerate(connected_topic_subgraphs)]\n",
    "grid = gridplot(plots, ncols=2)\n",
    "show(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are aiming to see big graphs with the most amount of seed nodes possible. Graphs with few seed nodes from the original term distribution will tend to be less representative of the original topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining the main component of each topic\n",
    "Now that we have the final subgraph for each topic, we will be applying several centrality measures to obtain the node that best represents the topic. In the following cell we have defined an auxiliary function that receives a list of algorithm and returns the results of applying them to obtain the best _n_ entities that represent each topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import networkx.algorithms as nxa\n",
    "\n",
    "from src.graph import get_centrality_algorithm_results\n",
    "\n",
    "def try_centrality_algorithms(topic_subgraphs, algorithms, stop_uris, top_n=4):\n",
    "    markdown = \"\"\n",
    "    for (algorithm, name) in algorithms:\n",
    "        print(f'Algorithm: {name}')\n",
    "        results = [get_centrality_algorithm_results(g, algorithm, stop_uris, top_n)\n",
    "                   for g in topic_subgraphs]\n",
    "        results_labels = [[(node[0]['label'], node[1]) for node in topic] \n",
    "                          for topic in results]\n",
    "        for idx, result in enumerate(results_labels):\n",
    "            print(f\"Topic {idx}:\", result)\n",
    "            print()\n",
    "        print()\n",
    "\n",
    "        \n",
    "algorithms = [\n",
    "    (nxa.centrality.information_centrality, \"Information centrality\"),\n",
    "    (nxa.centrality.eigenvector_centrality_numpy, \"Eigenvector centrality\"),\n",
    "    (nxa.centrality.closeness_centrality, \"Closeness centrality\"),\n",
    "    (nxa.centrality.betweenness_centrality, \"Betweenness centrality\"),\n",
    "    (nxa.centrality.communicability_betweenness_centrality, \"Communicability betweenness centrality\")\n",
    "]\n",
    "\n",
    "try_centrality_algorithms(connected_topic_subgraphs,\n",
    "               algorithms,\n",
    "               ['Q4167836', 'Q11862829'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add labels to LDA model\n",
    "Finally, we will be saving the best results to our LDA model that has been trained previously. Now, when we load the model again, after a topic has been inferred for a given text we will also be able to return a representative label for the topic, which will be also linked to Wikidata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.topic import Topic\n",
    "\n",
    "final_results = [get_centrality_algorithm_results(g,\n",
    "                                                 nxa.centrality.information_centrality,\n",
    "                                                ['Q4167836', 'Q11862829'], top_n=1)\n",
    "                 for g in connected_topic_subgraphs]\n",
    "\n",
    "final_results_topics = [Topic.from_node(topic[0], topic[1], \"lda\") \n",
    "                        for result in final_results for topic in result]\n",
    "lda_model = lda_pipe.named_steps['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.topic import LabelledTopicModel\n",
    "\n",
    "labelled_topic_model = LabelledTopicModel(lda_model, final_results_topics)\n",
    "\n",
    "lda_pipe.steps.pop()\n",
    "lda_pipe.steps.append(('model', labelled_topic_model))\n",
    "\n",
    "lda_pipe.transform([publications[-5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import save_object\n",
    "\n",
    "save_object(lda_pipe, os.path.join(NOTEBOOK_5_RESULTS_DIR, 'lda_pipe_with_labels.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
